{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etqpm7uRX1VI",
        "outputId": "5b5d6516-1a1b-4b11-a61f-31da9b696296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project-nmnbns'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 107 (delta 58), reused 76 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 73.29 KiB | 8.14 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Yasgant/project-nmnbns.git\n",
        "!cp ./project-nmnbns/game/* ./ -rf\n",
        "!pip install pygame\n",
        "!mkdir replay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YleYIyyplGc",
        "outputId": "9acc5284-32b5-4fc8-f7a8-a539ea7984bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxX1TWDRH2qN"
      },
      "outputs": [],
      "source": [
        "action_size = 9\n",
        "stack_size = 2\n",
        "learning_rate = 0.0025\n",
        "state_size = (101, 121, stack_size)\n",
        "total_episodes = 1000\n",
        "batch_size = 64\n",
        "gamma = 0.95\n",
        "remember_size = 100000\n",
        "pre_train = 5\n",
        "epsilon = 0.1\n",
        "new_img_size = (50, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc6CFoPC3eif",
        "outputId": "865a0837-e545-454a-d348-8bcae4e91115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random\n",
        "import sys\n",
        "sys.path.append('/content')\n",
        "from core import *\n",
        "from danmaku import *\n",
        "from enemies import *\n",
        "from tensorflow.keras import layers, optimizers, models\n",
        "import copy\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjW2RNrnImUX"
      },
      "outputs": [],
      "source": [
        "class MyModel:\n",
        "    def __init__(self, state_size = state_size, action_size = action_size, learning_rate = learning_rate):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = models.Sequential([\n",
        "            layers.Input(shape = (*new_img_size, stack_size)),\n",
        "            layers.Conv2D(filters = 32, kernel_size = 4),\n",
        "            layers.Conv2D(filters = 64, kernel_size = 2),\n",
        "            layers.Flatten(),\n",
        "            #layers.Dense(2048, activation = 'relu'),\n",
        "            #layers.Dense(2048, activation = 'relu'),\n",
        "            #layers.Dense(512, activation = 'relu'),\n",
        "            #layers.Dense(512, activation = 'relu'),\n",
        "            #layers.Dense(128, activation = 'relu'),\n",
        "            layers.Dense(512, activation = 'relu'),\n",
        "            layers.Dense(64, activation = 'relu'),\n",
        "            layers.Dense(action_size, activation = 'linear')\n",
        "        ])\n",
        "        self.model.compile(loss = 'mean_squared_error', optimizer = optimizers.Adam(learning_rate))\n",
        "    \n",
        "    def predict(self, img, eps = epsilon):\n",
        "        if np.random.random() < eps:\n",
        "            return np.random.randint(self.action_size)\n",
        "        return np.argmax(np.array(self.model(np.array([img])))[0])\n",
        "    \n",
        "    def predicts(self, imgs):\n",
        "        return np.array(self.model(imgs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4xWjUhsN9nP"
      },
      "outputs": [],
      "source": [
        "stacked_imgs = deque([np.zeros(new_img_size) for i in range(stack_size)], maxlen = stack_size)\n",
        "\n",
        "def stack_img(stacked_imgs, img, fir = False):\n",
        "    stacked_imgs.append(img)\n",
        "    if fir:\n",
        "        for i in range(stack_size - 1):\n",
        "            stacked_imgs.append(img)\n",
        "    stacked_img = np.stack(stacked_imgs, axis = 2)\n",
        "    return stacked_img, stacked_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBxQMUaOMGih"
      },
      "outputs": [],
      "source": [
        "class Memory:\n",
        "    def __init__(self, maxlen = remember_size):\n",
        "        self.queue = deque(maxlen = maxlen)\n",
        "    \n",
        "    def remember(self, img):\n",
        "        self.queue.append(img)\n",
        "    \n",
        "    def sample(self, size = batch_size):\n",
        "        return random.sample(self.queue, size)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def proc(img):\n",
        "    new_img = np.zeros(new_img_size)\n",
        "    x, y = 0, 0\n",
        "    flag = False\n",
        "    for i in range(len(img)):\n",
        "        for j in range(len(img[0])):\n",
        "            if img[i][j] == 0.3:\n",
        "                x, y = i, j\n",
        "                flag = True\n",
        "                break\n",
        "        if flag:\n",
        "            break\n",
        "    def in_map(x, y):\n",
        "        return 0 <= x < state_size[0] and 0 <= y < state_size[1]\n",
        "    for dx in range(-25, 25):\n",
        "        for dy in range(-25, 5):\n",
        "            if in_map(x+dx, y+dy):\n",
        "                new_img[25+dx, 25+dy] = img[x+dx, y+dy]\n",
        "            else:\n",
        "                new_img[25+dx, 25+dy] = 1\n",
        "    return new_img"
      ],
      "metadata": {
        "id": "NLAYYL_9xALr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KAlZV47NMVd"
      },
      "outputs": [],
      "source": [
        "data = StageData.empty('S1',10*60*60)\n",
        "# 0 ~ 1000\n",
        "data.insert(0, AimmingEnemy3(100, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(9, AimmingEnemy3(110, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(18, AimmingEnemy3(120, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(27, AimmingEnemy3(130, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(36, AimmingEnemy3(140, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(45, AimmingEnemy3(150, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(54, AimmingEnemy3(160, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(63, AimmingEnemy3(170, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(72, AimmingEnemy3(180, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "data.insert(81, AimmingEnemy3(190, 100, shoot_time = 10, bullet_speed=10, arc = np.pi / 24, alive_time=5*60))\n",
        "\n",
        "# 1000 ~ 1500\n",
        "data.insert(1000, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1020, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1040, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1060, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1080, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1100, AimmingEnemy(100, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1000, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1020, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1040, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1060, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1080, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "data.insert(1100, AimmingEnemy(300, 10, shoot_time = 2, bullet_speed=10, alive_time=3*60, vy = 3))\n",
        "\n",
        "# 1500 ~ 2500\n",
        "data.insert(1500, RandomEnemy(200, 100, shoot_time = 5, bullet_speed=5, alive_time=7*60))\n",
        "\n",
        "# 2500 ~ 3500\n",
        "data.insert(2500, RandomEnemyWithFall(200, 100, shoot_time = 5, bullet_speed=5, alive_time=7*60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfrKVv6eNDjn"
      },
      "outputs": [],
      "source": [
        "#pretrain\n",
        "memory = Memory()\n",
        "for i in range(pre_train):\n",
        "    G = game_with_op(Player(320, 400), copy.deepcopy(data))\n",
        "    flag = True\n",
        "    while True:\n",
        "        if flag:\n",
        "            img = G.get_img()\n",
        "            img = proc(img)\n",
        "            img, stacked_imgs = stack_img(stacked_imgs, img, True)\n",
        "            flag = False\n",
        "        action = np.random.randint(action_size)\n",
        "        reward, done = G.op(action)\n",
        "        next_img = G.get_img()\n",
        "        next_img = proc(next_img)\n",
        "        next_img, stacked_imgs = stack_img(stacked_imgs, next_img)\n",
        "        if done:\n",
        "            next_img = np.zeros((*new_img_size, stack_size))\n",
        "            memory.remember((img, action, reward, next_img))\n",
        "            break\n",
        "        memory.remember((img, action, reward, next_img))\n",
        "        img = next_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUMRGpbnWhH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0304528b-9c6c-4c78-bf48-8c9a753b98c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 finished! Frames: 125 Reward: -76577.4334505121\n",
            "Episode 1 finished! Frames: 164 Reward: -69701.83682688663\n",
            "Episode 2 finished! Frames: 86 Reward: -83359.46443605114\n",
            "Episode 3 finished! Frames: 56 Reward: -89067.71876304272\n",
            "Episode 4 finished! Frames: 93 Reward: -82225.71131911801\n",
            "Episode 5 finished! Frames: 71 Reward: -86215.72045924274\n",
            "Episode 6 finished! Frames: 86 Reward: -83468.19538484165\n",
            "Episode 7 finished! Frames: 110 Reward: -79117.75286446477\n",
            "Episode 8 finished! Frames: 123 Reward: -76982.34304272276\n",
            "Episode 9 finished! Frames: 117 Reward: -78054.22184875226\n",
            "Episode 10 finished! Frames: 114 Reward: -78415.82176474224\n",
            "Episode 11 finished! Frames: 130 Reward: -75768.14674911773\n",
            "Episode 12 finished! Frames: 65 Reward: -87348.63990873026\n",
            "Episode 13 finished! Frames: 47 Reward: -90817.62515451833\n",
            "Episode 14 finished! Frames: 56 Reward: -89065.77633152537\n",
            "Episode 15 finished! Frames: 86 Reward: -83401.38517172038\n",
            "Episode 16 finished! Frames: 85 Reward: -83645.33286480223\n",
            "Episode 17 finished! Frames: 73 Reward: -85815.43568318548\n",
            "Episode 18 finished! Frames: 82 Reward: -84100.83817384514\n",
            "Episode 19 finished! Frames: 58 Reward: -88659.34965100187\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 20 finished! Frames: 48 Reward: -90620.57711148758\n",
            "Episode 21 finished! Frames: 85 Reward: -83639.75009539389\n",
            "Episode 22 finished! Frames: 77 Reward: -85117.14009322532\n",
            "Episode 23 finished! Frames: 66 Reward: -87171.09747023211\n",
            "Episode 24 finished! Frames: 80 Reward: -84556.09119373087\n",
            "Episode 25 finished! Frames: 97 Reward: -81383.55046962404\n",
            "Episode 26 finished! Frames: 115 Reward: -78335.57628542266\n",
            "Episode 27 finished! Frames: 87 Reward: -83242.93871770136\n",
            "Episode 28 finished! Frames: 141 Reward: -73625.49534733317\n",
            "Episode 29 finished! Frames: 279 Reward: -49954.075137426764\n",
            "Episode 30 finished! Frames: 214 Reward: -61211.61094338649\n",
            "Episode 31 finished! Frames: 116 Reward: -78204.27428132277\n",
            "Episode 32 finished! Frames: 170 Reward: -70214.42630536042\n",
            "Episode 33 finished! Frames: 56 Reward: -89079.95184803671\n",
            "Episode 34 finished! Frames: 79 Reward: -84772.04690245634\n",
            "Episode 35 finished! Frames: 55 Reward: -89260.45662816995\n",
            "Episode 36 finished! Frames: 98 Reward: -81385.65291295477\n",
            "Episode 37 finished! Frames: 67 Reward: -86892.6122403368\n",
            "Episode 38 finished! Frames: 182 Reward: -68644.13216054029\n",
            "Episode 39 finished! Frames: 69 Reward: -86530.49307813431\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 40 finished! Frames: 92 Reward: -83061.8308778056\n",
            "Episode 41 finished! Frames: 112 Reward: -79428.28320433976\n",
            "Episode 42 finished! Frames: 148 Reward: -73243.3616115026\n",
            "Episode 43 finished! Frames: 59 Reward: -88444.48246766157\n",
            "Episode 44 finished! Frames: 112 Reward: -78739.9972914948\n",
            "Episode 45 finished! Frames: 168 Reward: -69431.53600772056\n",
            "Episode 46 finished! Frames: 59 Reward: -88480.27492969263\n",
            "Episode 47 finished! Frames: 149 Reward: -73861.08476872755\n",
            "Episode 48 finished! Frames: 252 Reward: -57222.380957428\n",
            "Episode 49 finished! Frames: 67 Reward: -86986.97265969047\n",
            "Episode 50 finished! Frames: 141 Reward: -73752.09945128039\n",
            "Episode 51 finished! Frames: 103 Reward: -80409.52988786067\n",
            "Episode 52 finished! Frames: 64 Reward: -87525.97400851914\n",
            "Episode 53 finished! Frames: 72 Reward: -86031.51820868978\n",
            "Episode 54 finished! Frames: 48 Reward: -90618.88144013644\n",
            "Episode 55 finished! Frames: 93 Reward: -82216.22861583388\n",
            "Episode 56 finished! Frames: 58 Reward: -88683.62549687145\n",
            "Episode 57 finished! Frames: 97 Reward: -81551.45422466547\n",
            "Episode 58 finished! Frames: 75 Reward: -85510.78498745065\n",
            "Episode 59 finished! Frames: 112 Reward: -78871.67479518008\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 60 finished! Frames: 126 Reward: -76715.46930891281\n",
            "Episode 61 finished! Frames: 174 Reward: -68510.7341880773\n",
            "Episode 62 finished! Frames: 101 Reward: -80710.52805419217\n",
            "Episode 63 finished! Frames: 49 Reward: -90422.20389043634\n",
            "Episode 64 finished! Frames: 77 Reward: -85094.5120933227\n",
            "Episode 65 finished! Frames: 1063 Reward: 62088.474591089034\n",
            "Episode 66 finished! Frames: 120 Reward: -77138.60564335273\n",
            "Episode 67 finished! Frames: 64 Reward: -87536.56445366486\n",
            "Episode 68 finished! Frames: 90 Reward: -82713.60030992441\n",
            "Episode 69 finished! Frames: 73 Reward: -85847.48096512574\n",
            "Episode 70 finished! Frames: 130 Reward: -75733.79397812032\n",
            "Episode 71 finished! Frames: 82 Reward: -84145.33289490303\n",
            "Episode 72 finished! Frames: 57 Reward: -88880.7060827852\n",
            "Episode 73 finished! Frames: 83 Reward: -83985.0555438289\n",
            "Episode 74 finished! Frames: 103 Reward: -80600.49838163274\n",
            "Episode 75 finished! Frames: 65 Reward: -87384.84198754274\n",
            "Episode 76 finished! Frames: 93 Reward: -82227.5367102466\n",
            "Episode 77 finished! Frames: 104 Reward: -80201.68388149941\n",
            "Episode 78 finished! Frames: 62 Reward: -87913.80313561353\n",
            "Episode 79 finished! Frames: 86 Reward: -83434.13097666134\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 80 finished! Frames: 116 Reward: -78081.8950957937\n",
            "Episode 81 finished! Frames: 98 Reward: -81295.65536496331\n",
            "Episode 82 finished! Frames: 64 Reward: -87521.86461414315\n",
            "Episode 83 finished! Frames: 67 Reward: -86982.88768612417\n",
            "Episode 84 finished! Frames: 66 Reward: -87174.50730516372\n",
            "Episode 85 finished! Frames: 116 Reward: -77913.0333270629\n",
            "Episode 86 finished! Frames: 97 Reward: -81497.77265043573\n",
            "Episode 87 finished! Frames: 122 Reward: -77062.3524123015\n",
            "Episode 88 finished! Frames: 98 Reward: -81329.88422365754\n",
            "Episode 89 finished! Frames: 100 Reward: -80848.01751219192\n",
            "Episode 90 finished! Frames: 72 Reward: -86019.78656780251\n",
            "Episode 91 finished! Frames: 64 Reward: -87538.85800639635\n",
            "Episode 92 finished! Frames: 56 Reward: -89059.713123371\n",
            "Episode 93 finished! Frames: 86 Reward: -83472.1565161494\n",
            "Episode 94 finished! Frames: 82 Reward: -84132.88198502737\n",
            "Episode 95 finished! Frames: 112 Reward: -78757.72623299214\n",
            "Episode 96 finished! Frames: 58 Reward: -88724.34044901164\n",
            "Episode 97 finished! Frames: 99 Reward: -81302.73158671496\n",
            "Episode 98 finished! Frames: 55 Reward: -89274.52492119533\n",
            "Episode 99 finished! Frames: 108 Reward: -79646.35523692449\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 100 finished! Frames: 109 Reward: -79472.1154812302\n",
            "Episode 101 finished! Frames: 51 Reward: -90055.50686998141\n",
            "Episode 102 finished! Frames: 66 Reward: -87167.3302761688\n",
            "Episode 103 finished! Frames: 67 Reward: -86960.24250540465\n",
            "Episode 104 finished! Frames: 84 Reward: -83750.41473139598\n",
            "Episode 105 finished! Frames: 52 Reward: -89850.93613941592\n",
            "Episode 106 finished! Frames: 55 Reward: -89281.3944772978\n",
            "Episode 107 finished! Frames: 92 Reward: -82434.92886414859\n",
            "Episode 108 finished! Frames: 100 Reward: -80958.80947273268\n",
            "Episode 109 finished! Frames: 120 Reward: -77346.56022646767\n",
            "Episode 110 finished! Frames: 86 Reward: -83366.3149897518\n",
            "Episode 111 finished! Frames: 123 Reward: -76894.04778090652\n",
            "Episode 112 finished! Frames: 143 Reward: -73577.0696775809\n",
            "Episode 113 finished! Frames: 58 Reward: -88679.01426241526\n",
            "Episode 114 finished! Frames: 58 Reward: -88660.56256462749\n",
            "Episode 115 finished! Frames: 89 Reward: -82912.8276715248\n",
            "Episode 116 finished! Frames: 69 Reward: -86561.03619448286\n",
            "Episode 117 finished! Frames: 70 Reward: -86395.70830134185\n",
            "Episode 118 finished! Frames: 47 Reward: -90816.33708916622\n",
            "Episode 119 finished! Frames: 116 Reward: -78149.57629104705\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 120 finished! Frames: 87 Reward: -83283.57473410436\n",
            "Episode 121 finished! Frames: 63 Reward: -87741.3727623954\n",
            "Episode 122 finished! Frames: 64 Reward: -87558.6347566204\n",
            "Episode 123 finished! Frames: 71 Reward: -86223.3541276146\n",
            "Episode 124 finished! Frames: 77 Reward: -85128.3373455056\n",
            "Episode 125 finished! Frames: 92 Reward: -82457.47724369161\n",
            "Episode 126 finished! Frames: 46 Reward: -91017.38521630364\n",
            "Episode 127 finished! Frames: 64 Reward: -87546.17829381021\n",
            "Episode 128 finished! Frames: 84 Reward: -83840.3274485609\n",
            "Episode 129 finished! Frames: 151 Reward: -72942.7062778041\n",
            "Episode 130 finished! Frames: 80 Reward: -84563.41969179269\n",
            "Episode 131 finished! Frames: 60 Reward: -88336.0411308565\n",
            "Episode 132 finished! Frames: 84 Reward: -83881.3828382992\n",
            "Episode 133 finished! Frames: 99 Reward: -80909.5226519402\n",
            "Episode 134 finished! Frames: 118 Reward: -77494.97097865847\n",
            "Episode 135 finished! Frames: 100 Reward: -80824.30270644237\n",
            "Episode 136 finished! Frames: 139 Reward: -74761.27961093455\n",
            "Episode 137 finished! Frames: 153 Reward: -72003.50313289816\n",
            "Episode 138 finished! Frames: 47 Reward: -90819.07399149229\n",
            "Episode 139 finished! Frames: 67 Reward: -86963.99680010212\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 140 finished! Frames: 61 Reward: -88096.174960377\n",
            "Episode 141 finished! Frames: 86 Reward: -83354.65777578033\n",
            "Episode 142 finished! Frames: 72 Reward: -86063.05170242024\n",
            "Episode 143 finished! Frames: 165 Reward: -70155.17106238197\n",
            "Episode 144 finished! Frames: 120 Reward: -77514.20300889602\n",
            "Episode 145 finished! Frames: 202 Reward: -64288.389250868204\n",
            "Episode 146 finished! Frames: 84 Reward: -83771.37089693247\n",
            "Episode 147 finished! Frames: 86 Reward: -84075.26394428007\n",
            "Episode 148 finished! Frames: 114 Reward: -78610.55397819518\n",
            "Episode 149 finished! Frames: 216 Reward: -62461.05372847689\n",
            "Episode 150 finished! Frames: 233 Reward: -59669.46302194515\n",
            "Episode 151 finished! Frames: 88 Reward: -83989.03170077375\n",
            "Episode 152 finished! Frames: 126 Reward: -76598.3659982283\n",
            "Episode 153 finished! Frames: 78 Reward: -85187.27774708139\n",
            "Episode 154 finished! Frames: 110 Reward: -79133.99631067392\n",
            "Episode 155 finished! Frames: 86 Reward: -83657.90850038055\n",
            "Episode 156 finished! Frames: 101 Reward: -80757.52838263742\n",
            "Episode 157 finished! Frames: 144 Reward: -73710.22065149719\n",
            "Episode 158 finished! Frames: 96 Reward: -81579.39440275401\n",
            "Episode 159 finished! Frames: 64 Reward: -87551.85466578617\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 160 finished! Frames: 82 Reward: -84670.23219880046\n",
            "Episode 161 finished! Frames: 92 Reward: -82425.0669714711\n",
            "Episode 162 finished! Frames: 96 Reward: -82180.42757099975\n",
            "Episode 163 finished! Frames: 246 Reward: -57026.251764165056\n",
            "Episode 164 finished! Frames: 64 Reward: -87540.26567934328\n",
            "Episode 165 finished! Frames: 296 Reward: -49662.917009547695\n",
            "Episode 166 finished! Frames: 118 Reward: -77644.15801170316\n",
            "Episode 167 finished! Frames: 107 Reward: -79776.69815101515\n",
            "Episode 168 finished! Frames: 58 Reward: -88673.28771113178\n",
            "Episode 169 finished! Frames: 47 Reward: -90817.75485986273\n",
            "Episode 170 finished! Frames: 174 Reward: -68549.49678973944\n",
            "Episode 171 finished! Frames: 63 Reward: -87737.97446599792\n",
            "Episode 172 finished! Frames: 72 Reward: -86033.23614705681\n",
            "Episode 173 finished! Frames: 115 Reward: -78470.9343014477\n",
            "Episode 174 finished! Frames: 120 Reward: -77664.94882243895\n",
            "Episode 175 finished! Frames: 60 Reward: -88284.03546187132\n",
            "Episode 176 finished! Frames: 333 Reward: -42586.07634058263\n",
            "Episode 177 finished! Frames: 101 Reward: -80680.27332589524\n",
            "Episode 178 finished! Frames: 130 Reward: -75911.15101827287\n",
            "Episode 179 finished! Frames: 147 Reward: -73266.95627108036\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 180 finished! Frames: 55 Reward: -89262.59733681355\n",
            "Episode 181 finished! Frames: 124 Reward: -76780.06378043424\n",
            "Episode 182 finished! Frames: 102 Reward: -80572.31637611821\n",
            "Episode 183 finished! Frames: 133 Reward: -76726.74988314869\n",
            "Episode 184 finished! Frames: 54 Reward: -89462.78083511893\n",
            "Episode 185 finished! Frames: 65 Reward: -87352.04761984212\n",
            "Episode 186 finished! Frames: 67 Reward: -86955.39130395741\n",
            "Episode 187 finished! Frames: 75 Reward: -85455.47837158635\n",
            "Episode 188 finished! Frames: 218 Reward: -63455.56872820812\n",
            "Episode 189 finished! Frames: 85 Reward: -83683.59620451697\n",
            "Episode 190 finished! Frames: 182 Reward: -67374.74036035113\n",
            "Episode 191 finished! Frames: 80 Reward: -84580.9972920534\n",
            "Episode 192 finished! Frames: 97 Reward: -81473.05803478904\n",
            "Episode 193 finished! Frames: 67 Reward: -86958.26048450824\n",
            "Episode 194 finished! Frames: 135 Reward: -74975.82218746052\n",
            "Episode 195 finished! Frames: 215 Reward: -61308.764128849056\n",
            "Episode 196 finished! Frames: 74 Reward: -85645.28173329077\n",
            "Episode 197 finished! Frames: 46 Reward: -91019.9343581111\n",
            "Episode 198 finished! Frames: 104 Reward: -80419.75882873466\n",
            "Episode 199 finished! Frames: 104 Reward: -80366.70576779197\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 200 finished! Frames: 73 Reward: -85876.92678178824\n",
            "Episode 201 finished! Frames: 88 Reward: -83119.18783307722\n",
            "Episode 202 finished! Frames: 96 Reward: -81689.66087135418\n",
            "Episode 203 finished! Frames: 94 Reward: -82007.88606794224\n",
            "Episode 204 finished! Frames: 101 Reward: -80746.60259737118\n",
            "Episode 205 finished! Frames: 76 Reward: -85478.35738046089\n",
            "Episode 206 finished! Frames: 128 Reward: -76587.5860124378\n",
            "Episode 207 finished! Frames: 103 Reward: -80622.2707619685\n",
            "Episode 208 finished! Frames: 99 Reward: -81156.34101615653\n",
            "Episode 209 finished! Frames: 74 Reward: -85645.86748081082\n",
            "Episode 210 finished! Frames: 85 Reward: -83775.79466767664\n",
            "Episode 211 finished! Frames: 96 Reward: -81656.60980245011\n",
            "Episode 212 finished! Frames: 264 Reward: -56816.75716594488\n",
            "Episode 213 finished! Frames: 88 Reward: -83688.42574858041\n",
            "Episode 214 finished! Frames: 105 Reward: -80202.4927822179\n",
            "Episode 215 finished! Frames: 95 Reward: -81922.3997143819\n",
            "Episode 216 finished! Frames: 126 Reward: -76670.80332717893\n",
            "Episode 217 finished! Frames: 136 Reward: -74987.40898324137\n",
            "Episode 218 finished! Frames: 75 Reward: -85504.85533589027\n",
            "Episode 219 finished! Frames: 73 Reward: -85892.76304827667\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 220 finished! Frames: 100 Reward: -81718.02233439118\n",
            "Episode 221 finished! Frames: 118 Reward: -77813.58863094842\n",
            "Episode 222 finished! Frames: 73 Reward: -85820.6047586526\n",
            "Episode 223 finished! Frames: 63 Reward: -87721.84999199068\n",
            "Episode 224 finished! Frames: 67 Reward: -86987.60416433027\n",
            "Episode 225 finished! Frames: 76 Reward: -85315.46662803696\n",
            "Episode 226 finished! Frames: 110 Reward: -79160.66584432601\n",
            "Episode 227 finished! Frames: 117 Reward: -77891.58306846693\n",
            "Episode 228 finished! Frames: 63 Reward: -87729.18576228444\n",
            "Episode 229 finished! Frames: 66 Reward: -87122.968685083\n",
            "Episode 230 finished! Frames: 131 Reward: -75732.24081172512\n",
            "Episode 231 finished! Frames: 147 Reward: -73136.97893301207\n",
            "Episode 232 finished! Frames: 65 Reward: -87338.85037162498\n",
            "Episode 233 finished! Frames: 87 Reward: -83240.45303474003\n",
            "Episode 234 finished! Frames: 94 Reward: -81964.59384097492\n",
            "Episode 235 finished! Frames: 108 Reward: -79448.08707620601\n",
            "Episode 236 finished! Frames: 141 Reward: -74237.28651081555\n",
            "Episode 237 finished! Frames: 136 Reward: -74954.64073171814\n",
            "Episode 238 finished! Frames: 81 Reward: -84366.26843136124\n",
            "Episode 239 finished! Frames: 91 Reward: -82315.98829419397\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 240 finished! Frames: 106 Reward: -79867.29436670693\n",
            "Episode 241 finished! Frames: 134 Reward: -75271.75418175712\n",
            "Episode 242 finished! Frames: 146 Reward: -73387.17442979553\n",
            "Episode 243 finished! Frames: 82 Reward: -84189.67224511346\n",
            "Episode 244 finished! Frames: 95 Reward: -81743.59127659636\n",
            "Episode 245 finished! Frames: 77 Reward: -84994.91758228165\n",
            "Episode 246 finished! Frames: 194 Reward: -66092.57162435411\n",
            "Episode 247 finished! Frames: 236 Reward: -58870.31499847366\n",
            "Episode 248 finished! Frames: 69 Reward: -86542.84596413159\n",
            "Episode 249 finished! Frames: 72 Reward: -86057.47152002729\n",
            "Episode 250 finished! Frames: 234 Reward: -58845.26247076765\n",
            "Episode 251 finished! Frames: 45 Reward: -91219.67990737315\n",
            "Episode 252 finished! Frames: 210 Reward: -63338.72375945487\n",
            "Episode 253 finished! Frames: 110 Reward: -79170.62458980456\n",
            "Episode 254 finished! Frames: 64 Reward: -87552.45671389077\n",
            "Episode 255 finished! Frames: 74 Reward: -85656.54089066363\n",
            "Episode 256 finished! Frames: 141 Reward: -74780.64338438261\n",
            "Episode 257 finished! Frames: 49 Reward: -90421.18558832159\n",
            "Episode 258 finished! Frames: 87 Reward: -83288.09961633025\n",
            "Episode 259 finished! Frames: 83 Reward: -84003.97417656651\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 260 finished! Frames: 99 Reward: -81023.36531586116\n",
            "Episode 261 finished! Frames: 56 Reward: -89064.02000612943\n",
            "Episode 262 finished! Frames: 62 Reward: -87954.4365989829\n",
            "Episode 263 finished! Frames: 211 Reward: -62688.36526682044\n",
            "Episode 264 finished! Frames: 91 Reward: -82763.94544995444\n",
            "Episode 265 finished! Frames: 238 Reward: -59471.38846858944\n",
            "Episode 266 finished! Frames: 80 Reward: -84605.4286461623\n",
            "Episode 267 finished! Frames: 160 Reward: -70461.98139052356\n",
            "Episode 268 finished! Frames: 236 Reward: -57853.35650063708\n",
            "Episode 269 finished! Frames: 108 Reward: -79305.31370011295\n",
            "Episode 270 finished! Frames: 95 Reward: -81837.67159823928\n",
            "Episode 271 finished! Frames: 129 Reward: -75926.67181678997\n",
            "Episode 272 finished! Frames: 119 Reward: -78076.14238824694\n",
            "Episode 273 finished! Frames: 115 Reward: -78497.86832540274\n",
            "Episode 274 finished! Frames: 75 Reward: -85420.63078311468\n",
            "Episode 275 finished! Frames: 263 Reward: -52879.389725490764\n",
            "Episode 276 finished! Frames: 107 Reward: -80612.18944525541\n",
            "Episode 277 finished! Frames: 118 Reward: -78604.97308496952\n",
            "Episode 278 finished! Frames: 110 Reward: -79283.98176283977\n",
            "Episode 279 finished! Frames: 117 Reward: -78185.95094216827\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 280 finished! Frames: 192 Reward: -65559.59172791732\n",
            "Episode 281 finished! Frames: 145 Reward: -73556.90255000348\n",
            "Episode 282 finished! Frames: 109 Reward: -79553.99512571539\n",
            "Episode 283 finished! Frames: 81 Reward: -84463.65719427848\n",
            "Episode 284 finished! Frames: 71 Reward: -86217.51723195091\n",
            "Episode 285 finished! Frames: 77 Reward: -85124.46875318598\n",
            "Episode 286 finished! Frames: 122 Reward: -77601.23717077555\n",
            "Episode 287 finished! Frames: 161 Reward: -70629.45137639728\n",
            "Episode 288 finished! Frames: 47 Reward: -90818.86000940326\n",
            "Episode 289 finished! Frames: 114 Reward: -78447.59247873517\n",
            "Episode 290 finished! Frames: 52 Reward: -89877.39183858322\n",
            "Episode 291 finished! Frames: 139 Reward: -74161.10368627767\n",
            "Episode 292 finished! Frames: 144 Reward: -73693.64447127454\n",
            "Episode 293 finished! Frames: 67 Reward: -86976.2281206979\n",
            "Episode 294 finished! Frames: 117 Reward: -78047.97813228382\n",
            "Episode 295 finished! Frames: 90 Reward: -82834.11062475391\n",
            "Episode 296 finished! Frames: 148 Reward: -72785.6744824097\n",
            "Episode 297 finished! Frames: 61 Reward: -88122.46339417133\n",
            "Episode 298 finished! Frames: 69 Reward: -86623.97096647529\n",
            "Episode 299 finished! Frames: 68 Reward: -86781.84638198516\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 300 finished! Frames: 92 Reward: -82381.31639341955\n",
            "Episode 301 finished! Frames: 69 Reward: -86586.48787646936\n",
            "Episode 302 finished! Frames: 116 Reward: -78202.00756755214\n",
            "Episode 303 finished! Frames: 99 Reward: -81089.98797125008\n",
            "Episode 304 finished! Frames: 97 Reward: -81520.94922517157\n",
            "Episode 305 finished! Frames: 91 Reward: -82541.08609326571\n",
            "Episode 306 finished! Frames: 97 Reward: -81411.85766987299\n",
            "Episode 307 finished! Frames: 72 Reward: -86039.78613673312\n",
            "Episode 308 finished! Frames: 111 Reward: -79122.98575462424\n",
            "Episode 309 finished! Frames: 78 Reward: -84922.81523132723\n",
            "Episode 310 finished! Frames: 134 Reward: -75324.18899056924\n",
            "Episode 311 finished! Frames: 81 Reward: -84389.15199185091\n",
            "Episode 312 finished! Frames: 94 Reward: -81989.94715270819\n",
            "Episode 313 finished! Frames: 91 Reward: -82597.25560712667\n",
            "Episode 314 finished! Frames: 75 Reward: -85531.1011995028\n",
            "Episode 315 finished! Frames: 72 Reward: -86023.58431164644\n",
            "Episode 316 finished! Frames: 84 Reward: -83805.29040154789\n",
            "Episode 317 finished! Frames: 73 Reward: -85830.89616459375\n",
            "Episode 318 finished! Frames: 95 Reward: -81804.35660446147\n",
            "Episode 319 finished! Frames: 186 Reward: -66600.50192605102\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 320 finished! Frames: 132 Reward: -75903.25824017503\n",
            "Episode 321 finished! Frames: 132 Reward: -75592.0302856477\n",
            "Episode 322 finished! Frames: 55 Reward: -89254.48831950108\n",
            "Episode 323 finished! Frames: 70 Reward: -86391.73292160784\n",
            "Episode 324 finished! Frames: 65 Reward: -87319.55484109119\n",
            "Episode 325 finished! Frames: 117 Reward: -77745.77798733248\n",
            "Episode 326 finished! Frames: 89 Reward: -82876.30922761007\n",
            "Episode 327 finished! Frames: 123 Reward: -77033.35915658546\n",
            "Episode 328 finished! Frames: 91 Reward: -82448.25826279126\n",
            "Episode 329 finished! Frames: 65 Reward: -87330.69411718073\n",
            "Episode 330 finished! Frames: 84 Reward: -83675.05152442174\n",
            "Episode 331 finished! Frames: 93 Reward: -82181.32931420096\n",
            "Episode 332 finished! Frames: 64 Reward: -87521.76715587388\n",
            "Episode 333 finished! Frames: 121 Reward: -77280.51043068251\n",
            "Episode 334 finished! Frames: 74 Reward: -85645.59319484036\n",
            "Episode 335 finished! Frames: 218 Reward: -61068.785178794504\n",
            "Episode 336 finished! Frames: 44 Reward: -91417.81649661105\n",
            "Episode 337 finished! Frames: 93 Reward: -82189.0168045284\n",
            "Episode 338 finished! Frames: 137 Reward: -74243.40421752437\n",
            "Episode 339 finished! Frames: 76 Reward: -85283.06616108396\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 340 finished! Frames: 107 Reward: -79650.76613763702\n",
            "Episode 341 finished! Frames: 102 Reward: -80629.31524695709\n",
            "Episode 342 finished! Frames: 74 Reward: -85666.77404948852\n",
            "Episode 343 finished! Frames: 209 Reward: -63100.25171030673\n",
            "Episode 344 finished! Frames: 90 Reward: -82770.75028739963\n",
            "Episode 345 finished! Frames: 56 Reward: -89075.55938970059\n",
            "Episode 346 finished! Frames: 72 Reward: -86038.58146897786\n",
            "Episode 347 finished! Frames: 118 Reward: -77831.91079313276\n",
            "Episode 348 finished! Frames: 104 Reward: -80241.288890175\n",
            "Episode 349 finished! Frames: 104 Reward: -80081.38491426766\n",
            "Episode 350 finished! Frames: 125 Reward: -76546.1205333695\n",
            "Episode 351 finished! Frames: 86 Reward: -83349.35361701976\n",
            "Episode 352 finished! Frames: 139 Reward: -74038.24507879607\n",
            "Episode 353 finished! Frames: 86 Reward: -83491.57951949195\n",
            "Episode 354 finished! Frames: 116 Reward: -78301.93509516091\n",
            "Episode 355 finished! Frames: 145 Reward: -72869.74966508077\n",
            "Episode 356 finished! Frames: 156 Reward: -72393.04700299032\n",
            "Episode 357 finished! Frames: 108 Reward: -79660.32755007589\n",
            "Episode 358 finished! Frames: 103 Reward: -80452.96519255058\n",
            "Episode 359 finished! Frames: 89 Reward: -82943.85277621703\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 360 finished! Frames: 151 Reward: -72732.6008825659\n",
            "Episode 361 finished! Frames: 102 Reward: -80648.85174335522\n",
            "Episode 362 finished! Frames: 112 Reward: -78860.24404285553\n",
            "Episode 363 finished! Frames: 82 Reward: -84173.92712084934\n",
            "Episode 364 finished! Frames: 85 Reward: -83643.57643304681\n",
            "Episode 365 finished! Frames: 65 Reward: -87361.75792368385\n",
            "Episode 366 finished! Frames: 121 Reward: -77313.96604223753\n",
            "Episode 367 finished! Frames: 151 Reward: -72594.82685877226\n",
            "Episode 368 finished! Frames: 70 Reward: -86433.32236779385\n",
            "Episode 369 finished! Frames: 63 Reward: -87731.82267498037\n",
            "Episode 370 finished! Frames: 80 Reward: -84661.38690055066\n",
            "Episode 371 finished! Frames: 89 Reward: -83006.05182338959\n",
            "Episode 372 finished! Frames: 73 Reward: -85879.97812925024\n",
            "Episode 373 finished! Frames: 92 Reward: -82356.7457673824\n",
            "Episode 374 finished! Frames: 87 Reward: -83218.216557081\n",
            "Episode 375 finished! Frames: 45 Reward: -91219.83400763471\n",
            "Episode 376 finished! Frames: 125 Reward: -76898.93728703016\n",
            "Episode 377 finished! Frames: 149 Reward: -72766.96072010342\n",
            "Episode 378 finished! Frames: 74 Reward: -85632.73921690842\n",
            "Episode 379 finished! Frames: 110 Reward: -79293.10751635776\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 380 finished! Frames: 157 Reward: -71334.07258130245\n",
            "Episode 381 finished! Frames: 61 Reward: -88151.00607820219\n",
            "Episode 382 finished! Frames: 73 Reward: -85906.97803632538\n",
            "Episode 383 finished! Frames: 74 Reward: -85647.4720019444\n",
            "Episode 384 finished! Frames: 71 Reward: -86250.99249817562\n",
            "Episode 385 finished! Frames: 190 Reward: -66035.58071605908\n",
            "Episode 386 finished! Frames: 63 Reward: -87723.57606310958\n",
            "Episode 387 finished! Frames: 109 Reward: -79612.34207632844\n",
            "Episode 388 finished! Frames: 90 Reward: -82704.21083300968\n",
            "Episode 389 finished! Frames: 179 Reward: -67554.85357675653\n",
            "Episode 390 finished! Frames: 200 Reward: -64649.61112958185\n",
            "Episode 391 finished! Frames: 84 Reward: -83700.24725772174\n",
            "Episode 392 finished! Frames: 164 Reward: -70358.5484800981\n",
            "Episode 393 finished! Frames: 85 Reward: -83521.83814546396\n",
            "Episode 394 finished! Frames: 138 Reward: -74447.9724631262\n",
            "Episode 395 finished! Frames: 94 Reward: -82012.26841531956\n",
            "Episode 396 finished! Frames: 65 Reward: -87370.6791014315\n",
            "Episode 397 finished! Frames: 113 Reward: -78609.22260499165\n",
            "Episode 398 finished! Frames: 125 Reward: -77126.76366025851\n",
            "Episode 399 finished! Frames: 92 Reward: -82473.08520229108\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 400 finished! Frames: 111 Reward: -79255.7919817962\n",
            "Episode 401 finished! Frames: 89 Reward: -82912.35263985713\n",
            "Episode 402 finished! Frames: 192 Reward: -65547.8264327864\n",
            "Episode 403 finished! Frames: 94 Reward: -81984.51871172324\n",
            "Episode 404 finished! Frames: 107 Reward: -79614.45472445637\n",
            "Episode 405 finished! Frames: 198 Reward: -65759.2022005815\n",
            "Episode 406 finished! Frames: 205 Reward: -63467.96243138794\n",
            "Episode 407 finished! Frames: 199 Reward: -64502.5760744269\n",
            "Episode 408 finished! Frames: 156 Reward: -71439.44996306697\n",
            "Episode 409 finished! Frames: 116 Reward: -78109.11678211755\n",
            "Episode 410 finished! Frames: 119 Reward: -77608.95469864915\n",
            "Episode 411 finished! Frames: 137 Reward: -74448.64341784758\n",
            "Episode 412 finished! Frames: 64 Reward: -87525.58316625623\n",
            "Episode 413 finished! Frames: 103 Reward: -80383.23458811767\n",
            "Episode 414 finished! Frames: 112 Reward: -78873.55288651952\n",
            "Episode 415 finished! Frames: 176 Reward: -68227.57461783642\n",
            "Episode 416 finished! Frames: 168 Reward: -68816.62980943269\n",
            "Episode 417 finished! Frames: 99 Reward: -81018.96676014621\n",
            "Episode 418 finished! Frames: 136 Reward: -74854.14972657843\n",
            "Episode 419 finished! Frames: 126 Reward: -76325.47378631604\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 420 finished! Frames: 64 Reward: -87523.37696739475\n",
            "Episode 421 finished! Frames: 74 Reward: -85637.43497686242\n",
            "Episode 422 finished! Frames: 82 Reward: -84173.71593648489\n",
            "Episode 423 finished! Frames: 68 Reward: -86707.27204336136\n",
            "Episode 424 finished! Frames: 90 Reward: -82587.59541574049\n",
            "Episode 425 finished! Frames: 71 Reward: -86166.1135629839\n",
            "Episode 426 finished! Frames: 99 Reward: -81020.12711488783\n",
            "Episode 427 finished! Frames: 105 Reward: -80089.32570332426\n",
            "Episode 428 finished! Frames: 82 Reward: -84291.4980042572\n",
            "Episode 429 finished! Frames: 74 Reward: -85627.72645024082\n",
            "Episode 430 finished! Frames: 139 Reward: -74679.45423892046\n",
            "Episode 431 finished! Frames: 80 Reward: -84596.05571705672\n",
            "Episode 432 finished! Frames: 189 Reward: -66304.04145874303\n",
            "Episode 433 finished! Frames: 59 Reward: -88488.00688792036\n",
            "Episode 434 finished! Frames: 180 Reward: -67208.92331811984\n",
            "Episode 435 finished! Frames: 110 Reward: -79053.14504387813\n",
            "Episode 436 finished! Frames: 112 Reward: -78565.86615567589\n",
            "Episode 437 finished! Frames: 57 Reward: -88881.3686016596\n",
            "Episode 438 finished! Frames: 111 Reward: -79116.31541221493\n",
            "Episode 439 finished! Frames: 95 Reward: -81602.83729045792\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 440 finished! Frames: 109 Reward: -79399.88881672834\n",
            "Episode 441 finished! Frames: 98 Reward: -81242.56952571294\n",
            "Episode 442 finished! Frames: 242 Reward: -58799.81948466037\n",
            "Episode 443 finished! Frames: 100 Reward: -80918.76497496897\n",
            "Episode 444 finished! Frames: 165 Reward: -70273.64980862282\n",
            "Episode 445 finished! Frames: 278 Reward: -51320.395049382365\n",
            "Episode 446 finished! Frames: 87 Reward: -83262.70902179688\n",
            "Episode 447 finished! Frames: 125 Reward: -76762.69337319437\n",
            "Episode 448 finished! Frames: 92 Reward: -83129.23917135836\n",
            "Episode 449 finished! Frames: 87 Reward: -83269.13396805825\n",
            "Episode 450 finished! Frames: 185 Reward: -66758.63247293103\n",
            "Episode 451 finished! Frames: 88 Reward: -83145.8205433887\n",
            "Episode 452 finished! Frames: 129 Reward: -75960.42973964378\n",
            "Episode 453 finished! Frames: 81 Reward: -84381.46311043848\n",
            "Episode 454 finished! Frames: 85 Reward: -83552.14697531344\n",
            "Episode 455 finished! Frames: 71 Reward: -86235.23396895968\n",
            "Episode 456 finished! Frames: 75 Reward: -85468.57323274383\n",
            "Episode 457 finished! Frames: 103 Reward: -80442.52185756883\n",
            "Episode 458 finished! Frames: 84 Reward: -83819.89948426886\n",
            "Episode 459 finished! Frames: 110 Reward: -79324.21266992093\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 460 finished! Frames: 47 Reward: -90819.78518378655\n",
            "Episode 461 finished! Frames: 89 Reward: -82908.54477865396\n",
            "Episode 462 finished! Frames: 106 Reward: -79796.0348300149\n",
            "Episode 463 finished! Frames: 63 Reward: -87768.93093746786\n",
            "Episode 464 finished! Frames: 123 Reward: -77067.9442154416\n",
            "Episode 465 finished! Frames: 132 Reward: -75595.60325284125\n",
            "Episode 466 finished! Frames: 99 Reward: -80932.55630082675\n",
            "Episode 467 finished! Frames: 111 Reward: -78958.74656716303\n",
            "Episode 468 finished! Frames: 143 Reward: -73375.12035549813\n",
            "Episode 469 finished! Frames: 98 Reward: -81345.8786189088\n",
            "Episode 470 finished! Frames: 78 Reward: -84888.94898274187\n",
            "Episode 471 finished! Frames: 125 Reward: -76546.16723388665\n",
            "Episode 472 finished! Frames: 123 Reward: -76937.42301941081\n",
            "Episode 473 finished! Frames: 82 Reward: -84104.30161334999\n",
            "Episode 474 finished! Frames: 161 Reward: -71143.21406570866\n",
            "Episode 475 finished! Frames: 96 Reward: -81798.46025606318\n",
            "Episode 476 finished! Frames: 56 Reward: -89070.70481255787\n",
            "Episode 477 finished! Frames: 116 Reward: -78003.36710226421\n",
            "Episode 478 finished! Frames: 98 Reward: -81274.40094753905\n",
            "Episode 479 finished! Frames: 83 Reward: -84005.10904472125\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 480 finished! Frames: 98 Reward: -81337.00585877363\n",
            "Episode 481 finished! Frames: 90 Reward: -82802.9388392666\n",
            "Episode 482 finished! Frames: 162 Reward: -70697.0809251545\n",
            "Episode 483 finished! Frames: 213 Reward: -62405.844615912174\n",
            "Episode 484 finished! Frames: 61 Reward: -88151.31072712227\n",
            "Episode 485 finished! Frames: 84 Reward: -83795.76640900485\n",
            "Episode 486 finished! Frames: 115 Reward: -78416.19765350064\n",
            "Episode 487 finished! Frames: 113 Reward: -78622.57500345015\n",
            "Episode 488 finished! Frames: 136 Reward: -74503.79757389886\n",
            "Episode 489 finished! Frames: 195 Reward: -64821.77693879504\n",
            "Episode 490 finished! Frames: 150 Reward: -72141.18915330205\n",
            "Episode 491 finished! Frames: 95 Reward: -81796.31945596679\n",
            "Episode 492 finished! Frames: 44 Reward: -91416.8897158312\n",
            "Episode 493 finished! Frames: 186 Reward: -67993.24526133771\n",
            "Episode 494 finished! Frames: 54 Reward: -89458.58992790933\n",
            "Episode 495 finished! Frames: 61 Reward: -88139.918693375\n",
            "Episode 496 finished! Frames: 88 Reward: -83122.76715782746\n",
            "Episode 497 finished! Frames: 136 Reward: -74726.45494067937\n",
            "Episode 498 finished! Frames: 91 Reward: -82550.91450501188\n",
            "Episode 499 finished! Frames: 55 Reward: -89258.20639372508\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 500 finished! Frames: 87 Reward: -83380.18446036984\n",
            "Episode 501 finished! Frames: 69 Reward: -86601.01566979056\n",
            "Episode 502 finished! Frames: 103 Reward: -80397.30707348275\n",
            "Episode 503 finished! Frames: 52 Reward: -89822.36569843633\n",
            "Episode 504 finished! Frames: 48 Reward: -90619.17410929446\n",
            "Episode 505 finished! Frames: 107 Reward: -79720.58141718045\n",
            "Episode 506 finished! Frames: 120 Reward: -77577.4928820407\n",
            "Episode 507 finished! Frames: 81 Reward: -84833.83330473391\n",
            "Episode 508 finished! Frames: 118 Reward: -77829.12070018337\n",
            "Episode 509 finished! Frames: 107 Reward: -79639.20048399168\n",
            "Episode 510 finished! Frames: 127 Reward: -76129.93628319657\n",
            "Episode 511 finished! Frames: 140 Reward: -74237.82837903287\n",
            "Episode 512 finished! Frames: 72 Reward: -86068.59848357966\n",
            "Episode 513 finished! Frames: 192 Reward: -65681.30668808834\n",
            "Episode 514 finished! Frames: 101 Reward: -80885.26689880266\n",
            "Episode 515 finished! Frames: 53 Reward: -89680.39640634588\n",
            "Episode 516 finished! Frames: 126 Reward: -76959.71945090033\n",
            "Episode 517 finished! Frames: 87 Reward: -83231.62998832311\n",
            "Episode 518 finished! Frames: 214 Reward: -62109.4926583318\n",
            "Episode 519 finished! Frames: 67 Reward: -86976.96143769247\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 520 finished! Frames: 78 Reward: -84839.24285281613\n",
            "Episode 521 finished! Frames: 64 Reward: -87556.58823379604\n",
            "Episode 522 finished! Frames: 84 Reward: -83793.87100714936\n",
            "Episode 523 finished! Frames: 122 Reward: -77052.723423336\n",
            "Episode 524 finished! Frames: 123 Reward: -76880.76834546193\n",
            "Episode 525 finished! Frames: 264 Reward: -54248.584160470105\n",
            "Episode 526 finished! Frames: 131 Reward: -75739.78886290337\n",
            "Episode 527 finished! Frames: 73 Reward: -85822.95034469577\n",
            "Episode 528 finished! Frames: 206 Reward: -63711.73075261324\n",
            "Episode 529 finished! Frames: 91 Reward: -82467.39429876945\n",
            "Episode 530 finished! Frames: 148 Reward: -72767.04810969031\n",
            "Episode 531 finished! Frames: 110 Reward: -79190.61905638134\n",
            "Episode 532 finished! Frames: 90 Reward: -82656.37645221417\n",
            "Episode 533 finished! Frames: 85 Reward: -83617.26729043793\n",
            "Episode 534 finished! Frames: 124 Reward: -76968.74185765561\n",
            "Episode 535 finished! Frames: 128 Reward: -76379.70440453096\n",
            "Episode 536 finished! Frames: 71 Reward: -86199.60271583384\n",
            "Episode 537 finished! Frames: 98 Reward: -81270.29793125144\n",
            "Episode 538 finished! Frames: 122 Reward: -77203.29593679556\n",
            "Episode 539 finished! Frames: 186 Reward: -66063.26725179172\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 540 finished! Frames: 69 Reward: -86608.12723579674\n",
            "Episode 541 finished! Frames: 115 Reward: -78298.85686683591\n",
            "Episode 542 finished! Frames: 259 Reward: -53588.11973629719\n",
            "Episode 543 finished! Frames: 84 Reward: -83821.84137129215\n",
            "Episode 544 finished! Frames: 104 Reward: -80063.68569528405\n",
            "Episode 545 finished! Frames: 169 Reward: -68857.6405120912\n",
            "Episode 546 finished! Frames: 93 Reward: -82061.72044027701\n",
            "Episode 547 finished! Frames: 119 Reward: -77883.804875959\n",
            "Episode 548 finished! Frames: 63 Reward: -87699.69967844502\n",
            "Episode 549 finished! Frames: 84 Reward: -83871.89508031572\n",
            "Episode 550 finished! Frames: 55 Reward: -89259.08979876638\n",
            "Episode 551 finished! Frames: 108 Reward: -79608.77182356676\n",
            "Episode 552 finished! Frames: 165 Reward: -70313.73794679332\n",
            "Episode 553 finished! Frames: 74 Reward: -85651.0097461215\n",
            "Episode 554 finished! Frames: 66 Reward: -87136.94705355947\n",
            "Episode 555 finished! Frames: 139 Reward: -74099.834827942\n",
            "Episode 556 finished! Frames: 91 Reward: -82496.19594885012\n",
            "Episode 557 finished! Frames: 84 Reward: -83775.726564288\n",
            "Episode 558 finished! Frames: 67 Reward: -86983.55552003594\n",
            "Episode 559 finished! Frames: 136 Reward: -74854.51031909336\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 560 finished! Frames: 153 Reward: -72107.54464433364\n",
            "Episode 561 finished! Frames: 154 Reward: -71875.54261917759\n",
            "Episode 562 finished! Frames: 152 Reward: -71881.90826471422\n",
            "Episode 563 finished! Frames: 88 Reward: -83018.21711126858\n",
            "Episode 564 finished! Frames: 47 Reward: -90820.01221710065\n",
            "Episode 565 finished! Frames: 115 Reward: -78500.41029787806\n",
            "Episode 566 finished! Frames: 73 Reward: -85865.95468472593\n",
            "Episode 567 finished! Frames: 111 Reward: -79165.59857332039\n",
            "Episode 568 finished! Frames: 127 Reward: -77442.99224007454\n",
            "Episode 569 finished! Frames: 143 Reward: -73506.800993792\n",
            "Episode 570 finished! Frames: 82 Reward: -84135.44070459469\n",
            "Episode 571 finished! Frames: 118 Reward: -77844.44640859404\n",
            "Episode 572 finished! Frames: 80 Reward: -84519.94849967137\n",
            "Episode 573 finished! Frames: 146 Reward: -72958.67633847299\n",
            "Episode 574 finished! Frames: 53 Reward: -89659.32250321434\n",
            "Episode 575 finished! Frames: 126 Reward: -76634.0808454999\n",
            "Episode 576 finished! Frames: 133 Reward: -75322.57691817879\n",
            "Episode 577 finished! Frames: 99 Reward: -82103.63163532723\n",
            "Episode 578 finished! Frames: 149 Reward: -72307.44984441866\n",
            "Episode 579 finished! Frames: 175 Reward: -68532.5988857344\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 580 finished! Frames: 56 Reward: -89062.59784850875\n",
            "Episode 581 finished! Frames: 134 Reward: -75266.26883828727\n",
            "Episode 582 finished! Frames: 180 Reward: -68420.32710048243\n",
            "Episode 583 finished! Frames: 95 Reward: -81624.8180063607\n",
            "Episode 584 finished! Frames: 57 Reward: -88886.14288771419\n",
            "Episode 585 finished! Frames: 176 Reward: -67760.90424882628\n",
            "Episode 586 finished! Frames: 126 Reward: -76559.83381661685\n",
            "Episode 587 finished! Frames: 67 Reward: -87013.22490792692\n",
            "Episode 588 finished! Frames: 118 Reward: -77947.59734812767\n",
            "Episode 589 finished! Frames: 115 Reward: -78316.89854042404\n",
            "Episode 590 finished! Frames: 85 Reward: -83604.50010093892\n",
            "Episode 591 finished! Frames: 138 Reward: -74282.93922397238\n",
            "Episode 592 finished! Frames: 165 Reward: -70202.03915542849\n",
            "Episode 593 finished! Frames: 87 Reward: -83317.48917952945\n",
            "Episode 594 finished! Frames: 47 Reward: -90816.98070621805\n",
            "Episode 595 finished! Frames: 107 Reward: -79780.78394367159\n",
            "Episode 596 finished! Frames: 95 Reward: -81897.41577910075\n",
            "Episode 597 finished! Frames: 188 Reward: -65409.585999407114\n",
            "Episode 598 finished! Frames: 109 Reward: -79346.09061904467\n",
            "Episode 599 finished! Frames: 71 Reward: -86211.51583379133\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 600 finished! Frames: 93 Reward: -82163.29013793096\n",
            "Episode 601 finished! Frames: 353 Reward: -40124.20674041107\n",
            "Episode 602 finished! Frames: 128 Reward: -75673.51014081096\n",
            "Episode 603 finished! Frames: 56 Reward: -89058.78017677239\n",
            "Episode 604 finished! Frames: 84 Reward: -83851.91326550554\n",
            "Episode 605 finished! Frames: 149 Reward: -72507.9711719244\n",
            "Episode 606 finished! Frames: 94 Reward: -81974.3147526902\n",
            "Episode 607 finished! Frames: 154 Reward: -71573.02293244607\n",
            "Episode 608 finished! Frames: 55 Reward: -89255.10069593202\n",
            "Episode 609 finished! Frames: 158 Reward: -70975.54940698092\n",
            "Episode 610 finished! Frames: 105 Reward: -79919.10123546628\n",
            "Episode 611 finished! Frames: 74 Reward: -85666.49998411436\n",
            "Episode 612 finished! Frames: 123 Reward: -76810.40308554673\n",
            "Episode 613 finished! Frames: 63 Reward: -87740.77602075959\n",
            "Episode 614 finished! Frames: 79 Reward: -84773.42249962033\n",
            "Episode 615 finished! Frames: 1067 Reward: 97274.3804176935\n",
            "Episode 616 finished! Frames: 65 Reward: -87361.5230839349\n",
            "Episode 617 finished! Frames: 44 Reward: -91419.72904368157\n",
            "Episode 618 finished! Frames: 97 Reward: -81466.95505238597\n",
            "Episode 619 finished! Frames: 222 Reward: -60614.083997084155\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 620 finished! Frames: 79 Reward: -84752.3329741179\n",
            "Episode 621 finished! Frames: 159 Reward: -72169.48282633457\n",
            "Episode 622 finished! Frames: 169 Reward: -69373.32223775095\n",
            "Episode 623 finished! Frames: 55 Reward: -89255.89746065105\n",
            "Episode 624 finished! Frames: 84 Reward: -83839.60699661016\n",
            "Episode 625 finished! Frames: 75 Reward: -85504.12464006768\n",
            "Episode 626 finished! Frames: 127 Reward: -76252.72871527882\n",
            "Episode 627 finished! Frames: 135 Reward: -75627.85986223996\n",
            "Episode 628 finished! Frames: 263 Reward: -54599.147197616374\n",
            "Episode 629 finished! Frames: 159 Reward: -71627.90731823104\n",
            "Episode 630 finished! Frames: 94 Reward: -81971.62843026532\n",
            "Episode 631 finished! Frames: 64 Reward: -87537.82446950277\n",
            "Episode 632 finished! Frames: 73 Reward: -85828.5970511504\n",
            "Episode 633 finished! Frames: 45 Reward: -91216.7909629087\n",
            "Episode 634 finished! Frames: 180 Reward: -67045.11659338369\n",
            "Episode 635 finished! Frames: 119 Reward: -77630.56233865049\n",
            "Episode 636 finished! Frames: 72 Reward: -85980.94372696964\n",
            "Episode 637 finished! Frames: 81 Reward: -84367.87176906403\n",
            "Episode 638 finished! Frames: 129 Reward: -75891.37083094713\n",
            "Episode 639 finished! Frames: 289 Reward: -48895.78964745224\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 640 finished! Frames: 60 Reward: -88291.55865359744\n",
            "Episode 641 finished! Frames: 109 Reward: -79223.77120021508\n",
            "Episode 642 finished! Frames: 106 Reward: -79888.88849769073\n",
            "Episode 643 finished! Frames: 138 Reward: -74441.10035917937\n",
            "Episode 644 finished! Frames: 119 Reward: -77484.94741696301\n",
            "Episode 645 finished! Frames: 70 Reward: -86449.39092221783\n",
            "Episode 646 finished! Frames: 68 Reward: -86738.93413079383\n",
            "Episode 647 finished! Frames: 86 Reward: -83410.17701122127\n",
            "Episode 648 finished! Frames: 65 Reward: -87309.11548146253\n",
            "Episode 649 finished! Frames: 55 Reward: -89274.53155167503\n",
            "Episode 650 finished! Frames: 72 Reward: -86011.03811892566\n",
            "Episode 651 finished! Frames: 156 Reward: -72110.73901400194\n",
            "Episode 652 finished! Frames: 149 Reward: -72498.26879920506\n",
            "Episode 653 finished! Frames: 182 Reward: -66483.20138595291\n",
            "Episode 654 finished! Frames: 134 Reward: -74687.58856617888\n",
            "Episode 655 finished! Frames: 155 Reward: -71246.56559843532\n",
            "Episode 656 finished! Frames: 141 Reward: -73877.06042028294\n",
            "Episode 657 finished! Frames: 58 Reward: -88678.64230160989\n",
            "Episode 658 finished! Frames: 74 Reward: -85623.70046637265\n",
            "Episode 659 finished! Frames: 134 Reward: -74913.0090600946\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 660 finished! Frames: 166 Reward: -69768.39209047382\n",
            "Episode 661 finished! Frames: 65 Reward: -87333.54832801934\n",
            "Episode 662 finished! Frames: 169 Reward: -70161.70602947191\n",
            "Episode 663 finished! Frames: 80 Reward: -84510.87040674618\n",
            "Episode 664 finished! Frames: 139 Reward: -73786.97460589424\n",
            "Episode 665 finished! Frames: 89 Reward: -82899.42229586843\n",
            "Episode 666 finished! Frames: 287 Reward: -48706.84804544754\n",
            "Episode 667 finished! Frames: 142 Reward: -74073.76408333461\n",
            "Episode 668 finished! Frames: 131 Reward: -75716.42696511469\n",
            "Episode 669 finished! Frames: 95 Reward: -81966.420250046\n",
            "Episode 670 finished! Frames: 109 Reward: -79435.41855924377\n",
            "Episode 671 finished! Frames: 85 Reward: -83605.2579908239\n",
            "Episode 672 finished! Frames: 73 Reward: -85865.88026254904\n",
            "Episode 673 finished! Frames: 114 Reward: -78475.57904624243\n",
            "Episode 674 finished! Frames: 71 Reward: -86205.07816224147\n",
            "Episode 675 finished! Frames: 95 Reward: -81884.00538415342\n",
            "Episode 676 finished! Frames: 64 Reward: -87538.19475885127\n",
            "Episode 677 finished! Frames: 250 Reward: -54765.412098780675\n",
            "Episode 678 finished! Frames: 195 Reward: -66179.00955735563\n",
            "Episode 679 finished! Frames: 123 Reward: -78218.46607485496\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 680 finished! Frames: 96 Reward: -81707.30169015614\n",
            "Episode 681 finished! Frames: 139 Reward: -74277.31494017682\n",
            "Episode 682 finished! Frames: 144 Reward: -73455.38179983699\n",
            "Episode 683 finished! Frames: 67 Reward: -86925.50317206109\n",
            "Episode 684 finished! Frames: 134 Reward: -75104.11537589433\n",
            "Episode 685 finished! Frames: 111 Reward: -79011.55013216726\n",
            "Episode 686 finished! Frames: 131 Reward: -75525.93571005992\n",
            "Episode 687 finished! Frames: 144 Reward: -74087.00846219323\n",
            "Episode 688 finished! Frames: 123 Reward: -77108.42828666371\n",
            "Episode 689 finished! Frames: 156 Reward: -72494.80958686183\n",
            "Episode 690 finished! Frames: 65 Reward: -87352.20734441499\n",
            "Episode 691 finished! Frames: 97 Reward: -81535.77949381014\n",
            "Episode 692 finished! Frames: 63 Reward: -87727.68140083792\n",
            "Episode 693 finished! Frames: 80 Reward: -84578.11477370317\n",
            "Episode 694 finished! Frames: 92 Reward: -82252.20225431991\n",
            "Episode 695 finished! Frames: 132 Reward: -75327.06862035616\n",
            "Episode 696 finished! Frames: 121 Reward: -76961.35128299052\n",
            "Episode 697 finished! Frames: 62 Reward: -87924.36688728089\n",
            "Episode 698 finished! Frames: 215 Reward: -61055.35080411454\n",
            "Episode 699 finished! Frames: 68 Reward: -86773.30435120582\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 700 finished! Frames: 105 Reward: -80194.10393021375\n",
            "Episode 701 finished! Frames: 65 Reward: -87353.29984247035\n",
            "Episode 702 finished! Frames: 90 Reward: -82782.33560767128\n",
            "Episode 703 finished! Frames: 64 Reward: -87490.14127407515\n",
            "Episode 704 finished! Frames: 225 Reward: -61127.77790485159\n",
            "Episode 705 finished! Frames: 78 Reward: -84910.99311050159\n",
            "Episode 706 finished! Frames: 159 Reward: -71007.0742538811\n",
            "Episode 707 finished! Frames: 165 Reward: -70384.51297568396\n",
            "Episode 708 finished! Frames: 96 Reward: -81681.71333494467\n",
            "Episode 709 finished! Frames: 167 Reward: -70249.65880855992\n",
            "Episode 710 finished! Frames: 86 Reward: -83456.46373242149\n",
            "Episode 711 finished! Frames: 86 Reward: -83475.43743429155\n",
            "Episode 712 finished! Frames: 92 Reward: -82365.24895684722\n",
            "Episode 713 finished! Frames: 120 Reward: -78348.95135801689\n",
            "Episode 714 finished! Frames: 75 Reward: -85437.05216302937\n",
            "Episode 715 finished! Frames: 71 Reward: -86276.6454427261\n",
            "Episode 716 finished! Frames: 176 Reward: -68488.96978314222\n",
            "Episode 717 finished! Frames: 106 Reward: -80696.82503979532\n",
            "Episode 718 finished! Frames: 108 Reward: -79492.1109028451\n",
            "Episode 719 finished! Frames: 96 Reward: -81570.49268145692\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 720 finished! Frames: 212 Reward: -62374.99850669394\n",
            "Episode 721 finished! Frames: 81 Reward: -84370.20570804334\n",
            "Episode 722 finished! Frames: 67 Reward: -86987.77711779416\n",
            "Episode 723 finished! Frames: 129 Reward: -76285.77335635392\n",
            "Episode 724 finished! Frames: 102 Reward: -80625.95380437159\n",
            "Episode 725 finished! Frames: 92 Reward: -82441.12219117349\n",
            "Episode 726 finished! Frames: 91 Reward: -82612.8783815155\n",
            "Episode 727 finished! Frames: 123 Reward: -76903.52381941053\n",
            "Episode 728 finished! Frames: 90 Reward: -82749.90354833988\n",
            "Episode 729 finished! Frames: 47 Reward: -90816.97539563713\n",
            "Episode 730 finished! Frames: 94 Reward: -81867.82420373273\n",
            "Episode 731 finished! Frames: 67 Reward: -86958.62411539232\n",
            "Episode 732 finished! Frames: 69 Reward: -86583.01059619094\n",
            "Episode 733 finished! Frames: 84 Reward: -83871.40615602717\n",
            "Episode 734 finished! Frames: 146 Reward: -73681.68567372055\n",
            "Episode 735 finished! Frames: 99 Reward: -80972.19445674263\n",
            "Episode 736 finished! Frames: 130 Reward: -77514.56791101127\n",
            "Episode 737 finished! Frames: 107 Reward: -79585.12733922873\n",
            "Episode 738 finished! Frames: 173 Reward: -68921.33761816121\n",
            "Episode 739 finished! Frames: 149 Reward: -72616.34714599597\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 740 finished! Frames: 88 Reward: -82972.32257160523\n",
            "Episode 741 finished! Frames: 70 Reward: -86440.04050646296\n",
            "Episode 742 finished! Frames: 182 Reward: -67145.17242390948\n",
            "Episode 743 finished! Frames: 105 Reward: -79953.42536796325\n",
            "Episode 744 finished! Frames: 138 Reward: -74463.61934444007\n",
            "Episode 745 finished! Frames: 150 Reward: -73238.36981757285\n",
            "Episode 746 finished! Frames: 245 Reward: -56892.77742873744\n",
            "Episode 747 finished! Frames: 62 Reward: -87931.3327263318\n",
            "Episode 748 finished! Frames: 89 Reward: -82924.74285110929\n",
            "Episode 749 finished! Frames: 94 Reward: -82065.68945684958\n",
            "Episode 750 finished! Frames: 105 Reward: -79980.65088039612\n",
            "Episode 751 finished! Frames: 120 Reward: -77523.96394922577\n",
            "Episode 752 finished! Frames: 161 Reward: -69846.82147970572\n",
            "Episode 753 finished! Frames: 72 Reward: -86017.16859544336\n",
            "Episode 754 finished! Frames: 54 Reward: -89452.63214609268\n",
            "Episode 755 finished! Frames: 118 Reward: -77499.41642047737\n",
            "Episode 756 finished! Frames: 183 Reward: -66598.54792298304\n",
            "Episode 757 finished! Frames: 47 Reward: -90817.23485986273\n",
            "Episode 758 finished! Frames: 59 Reward: -88459.53222130262\n",
            "Episode 759 finished! Frames: 70 Reward: -86389.16478933026\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 760 finished! Frames: 125 Reward: -76658.7416813663\n",
            "Episode 761 finished! Frames: 95 Reward: -81802.75478932055\n",
            "Episode 762 finished! Frames: 120 Reward: -77675.83495680254\n",
            "Episode 763 finished! Frames: 71 Reward: -86227.01063317935\n",
            "Episode 764 finished! Frames: 129 Reward: -76458.81411764346\n",
            "Episode 765 finished! Frames: 109 Reward: -79574.22023770754\n",
            "Episode 766 finished! Frames: 332 Reward: -40585.37407659075\n",
            "Episode 767 finished! Frames: 209 Reward: -62313.70682058934\n",
            "Episode 768 finished! Frames: 49 Reward: -90419.79722104633\n",
            "Episode 769 finished! Frames: 100 Reward: -80745.10036971403\n",
            "Episode 770 finished! Frames: 116 Reward: -77849.93198728182\n",
            "Episode 771 finished! Frames: 117 Reward: -77938.53016053315\n",
            "Episode 772 finished! Frames: 193 Reward: -64940.594976995344\n",
            "Episode 773 finished! Frames: 74 Reward: -85679.09372500319\n",
            "Episode 774 finished! Frames: 47 Reward: -90817.84902703113\n",
            "Episode 775 finished! Frames: 73 Reward: -85853.90847219453\n",
            "Episode 776 finished! Frames: 98 Reward: -81360.34955251671\n",
            "Episode 777 finished! Frames: 114 Reward: -78736.58082697503\n",
            "Episode 778 finished! Frames: 71 Reward: -86216.94078656874\n",
            "Episode 779 finished! Frames: 226 Reward: -59050.26925728738\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 780 finished! Frames: 116 Reward: -78258.11809159104\n",
            "Episode 781 finished! Frames: 118 Reward: -77606.9671422662\n",
            "Episode 782 finished! Frames: 69 Reward: -86577.77920260708\n",
            "Episode 783 finished! Frames: 121 Reward: -77259.94343980367\n",
            "Episode 784 finished! Frames: 80 Reward: -84600.55704228987\n",
            "Episode 785 finished! Frames: 52 Reward: -89878.01415556422\n",
            "Episode 786 finished! Frames: 89 Reward: -82915.677699132\n",
            "Episode 787 finished! Frames: 104 Reward: -80282.62614722742\n",
            "Episode 788 finished! Frames: 89 Reward: -82825.90555463647\n",
            "Episode 789 finished! Frames: 146 Reward: -73181.28602754953\n",
            "Episode 790 finished! Frames: 123 Reward: -76916.52208758265\n",
            "Episode 791 finished! Frames: 161 Reward: -70796.79109146589\n",
            "Episode 792 finished! Frames: 112 Reward: -79482.22588072234\n",
            "Episode 793 finished! Frames: 113 Reward: -78589.8723876337\n",
            "Episode 794 finished! Frames: 103 Reward: -81035.9937961618\n",
            "Episode 795 finished! Frames: 104 Reward: -80112.38929830512\n",
            "Episode 796 finished! Frames: 73 Reward: -85875.37406828075\n",
            "Episode 797 finished! Frames: 65 Reward: -87342.1308029512\n",
            "Episode 798 finished! Frames: 156 Reward: -71275.0038154794\n",
            "Episode 799 finished! Frames: 95 Reward: -81892.74239544138\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 800 finished! Frames: 153 Reward: -71642.33809338011\n",
            "Episode 801 finished! Frames: 79 Reward: -84690.29310714868\n",
            "Episode 802 finished! Frames: 90 Reward: -82742.80957724137\n",
            "Episode 803 finished! Frames: 92 Reward: -82302.49082228284\n",
            "Episode 804 finished! Frames: 78 Reward: -84860.00212491347\n",
            "Episode 805 finished! Frames: 140 Reward: -74117.19702664364\n",
            "Episode 806 finished! Frames: 105 Reward: -80043.75820787415\n",
            "Episode 807 finished! Frames: 151 Reward: -72631.5880175762\n",
            "Episode 808 finished! Frames: 63 Reward: -87729.46356487038\n",
            "Episode 809 finished! Frames: 55 Reward: -89260.74967720293\n",
            "Episode 810 finished! Frames: 66 Reward: -87120.28031644349\n",
            "Episode 811 finished! Frames: 102 Reward: -80601.75724440214\n",
            "Episode 812 finished! Frames: 116 Reward: -78015.61629977034\n",
            "Episode 813 finished! Frames: 46 Reward: -91017.62924030749\n",
            "Episode 814 finished! Frames: 56 Reward: -89081.90750427927\n",
            "Episode 815 finished! Frames: 151 Reward: -72172.23519553317\n",
            "Episode 816 finished! Frames: 65 Reward: -87378.22307531403\n",
            "Episode 817 finished! Frames: 207 Reward: -63510.649324661514\n",
            "Episode 818 finished! Frames: 152 Reward: -72601.27579718828\n",
            "Episode 819 finished! Frames: 65 Reward: -87370.92206784818\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 820 finished! Frames: 96 Reward: -81652.93343967138\n",
            "Episode 821 finished! Frames: 187 Reward: -65931.1059575069\n",
            "Episode 822 finished! Frames: 80 Reward: -84593.9756201384\n",
            "Episode 823 finished! Frames: 81 Reward: -84374.85982590835\n",
            "Episode 824 finished! Frames: 82 Reward: -84176.48104494545\n",
            "Episode 825 finished! Frames: 156 Reward: -71524.65247412595\n",
            "Episode 826 finished! Frames: 165 Reward: -69703.7131389842\n",
            "Episode 827 finished! Frames: 146 Reward: -73339.39402544036\n",
            "Episode 828 finished! Frames: 83 Reward: -83955.0903294003\n",
            "Episode 829 finished! Frames: 80 Reward: -84528.93122276643\n",
            "Episode 830 finished! Frames: 162 Reward: -70247.29896451306\n",
            "Episode 831 finished! Frames: 61 Reward: -88126.07003735118\n",
            "Episode 832 finished! Frames: 345 Reward: -39967.965482321204\n",
            "Episode 833 finished! Frames: 63 Reward: -87722.02190225526\n",
            "Episode 834 finished! Frames: 96 Reward: -81921.80026398788\n",
            "Episode 835 finished! Frames: 235 Reward: -59490.73319402744\n",
            "Episode 836 finished! Frames: 95 Reward: -81895.51436633816\n",
            "Episode 837 finished! Frames: 115 Reward: -78358.57468868654\n",
            "Episode 838 finished! Frames: 204 Reward: -63765.86643751584\n",
            "Episode 839 finished! Frames: 89 Reward: -82882.57654645437\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 840 finished! Frames: 85 Reward: -83652.55999032308\n",
            "Episode 841 finished! Frames: 163 Reward: -69795.44990662654\n",
            "Episode 842 finished! Frames: 201 Reward: -64242.5285298218\n",
            "Episode 843 finished! Frames: 92 Reward: -82193.99793475893\n",
            "Episode 844 finished! Frames: 95 Reward: -81878.40416432699\n",
            "Episode 845 finished! Frames: 159 Reward: -71170.32490770776\n",
            "Episode 846 finished! Frames: 115 Reward: -79248.3566813291\n",
            "Episode 847 finished! Frames: 66 Reward: -87168.66189118412\n",
            "Episode 848 finished! Frames: 47 Reward: -90817.06276437231\n",
            "Episode 849 finished! Frames: 53 Reward: -89656.17727607187\n",
            "Episode 850 finished! Frames: 62 Reward: -87922.62924202897\n",
            "Episode 851 finished! Frames: 107 Reward: -79676.28056498346\n",
            "Episode 852 finished! Frames: 87 Reward: -83336.20900437197\n",
            "Episode 853 finished! Frames: 65 Reward: -87340.448833698\n",
            "Episode 854 finished! Frames: 181 Reward: -67195.50343482864\n",
            "Episode 855 finished! Frames: 72 Reward: -86061.4028727496\n",
            "Episode 856 finished! Frames: 69 Reward: -86632.16868611716\n",
            "Episode 857 finished! Frames: 71 Reward: -86206.0245931651\n",
            "Episode 858 finished! Frames: 87 Reward: -83293.5693780552\n",
            "Episode 859 finished! Frames: 87 Reward: -83372.24156393041\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 860 finished! Frames: 92 Reward: -82471.5199182823\n",
            "Episode 861 finished! Frames: 200 Reward: -64940.1459902866\n",
            "Episode 862 finished! Frames: 97 Reward: -81572.08340245027\n",
            "Episode 863 finished! Frames: 84 Reward: -83743.13913812523\n",
            "Episode 864 finished! Frames: 233 Reward: -59374.82990035197\n",
            "Episode 865 finished! Frames: 49 Reward: -90420.28109455948\n",
            "Episode 866 finished! Frames: 79 Reward: -84679.54150913889\n",
            "Episode 867 finished! Frames: 70 Reward: -86437.58583503164\n",
            "Episode 868 finished! Frames: 211 Reward: -62427.77904600912\n",
            "Episode 869 finished! Frames: 187 Reward: -66098.15203746702\n",
            "Episode 870 finished! Frames: 147 Reward: -72502.95333949206\n",
            "Episode 871 finished! Frames: 67 Reward: -86972.57625005678\n",
            "Episode 872 finished! Frames: 181 Reward: -67726.87427149263\n",
            "Episode 873 finished! Frames: 117 Reward: -77975.77151267591\n",
            "Episode 874 finished! Frames: 174 Reward: -68513.37144131522\n",
            "Episode 875 finished! Frames: 135 Reward: -75224.3288405656\n",
            "Episode 876 finished! Frames: 1042 Reward: 99670.60200320743\n",
            "Episode 877 finished! Frames: 98 Reward: -81342.88112309392\n",
            "Episode 878 finished! Frames: 83 Reward: -84010.96659626486\n",
            "Episode 879 finished! Frames: 115 Reward: -78359.34981283123\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 880 finished! Frames: 106 Reward: -79876.51344199706\n",
            "Episode 881 finished! Frames: 55 Reward: -89264.85963974147\n",
            "Episode 882 finished! Frames: 105 Reward: -80411.00270735972\n",
            "Episode 883 finished! Frames: 214 Reward: -62239.582332769074\n",
            "Episode 884 finished! Frames: 107 Reward: -79823.23751523212\n",
            "Episode 885 finished! Frames: 106 Reward: -79855.25199156944\n",
            "Episode 886 finished! Frames: 81 Reward: -84462.07268626882\n",
            "Episode 887 finished! Frames: 139 Reward: -74104.42944393243\n",
            "Episode 888 finished! Frames: 54 Reward: -89459.69829624801\n",
            "Episode 889 finished! Frames: 118 Reward: -77792.73327504953\n",
            "Episode 890 finished! Frames: 103 Reward: -80487.92114365057\n",
            "Episode 891 finished! Frames: 236 Reward: -57448.83775198351\n",
            "Episode 892 finished! Frames: 164 Reward: -70430.6855389158\n",
            "Episode 893 finished! Frames: 144 Reward: -73334.61008304567\n",
            "Episode 894 finished! Frames: 104 Reward: -80232.2469500677\n",
            "Episode 895 finished! Frames: 122 Reward: -77232.58540661914\n",
            "Episode 896 finished! Frames: 85 Reward: -83759.64465078237\n",
            "Episode 897 finished! Frames: 75 Reward: -85461.9235322833\n",
            "Episode 898 finished! Frames: 97 Reward: -81539.25534344639\n",
            "Episode 899 finished! Frames: 70 Reward: -86450.05200421115\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 900 finished! Frames: 46 Reward: -91017.95983306631\n",
            "Episode 901 finished! Frames: 65 Reward: -87358.23701927523\n",
            "Episode 902 finished! Frames: 81 Reward: -84379.39724597953\n",
            "Episode 903 finished! Frames: 140 Reward: -74128.33780584033\n",
            "Episode 904 finished! Frames: 74 Reward: -85636.64940684507\n",
            "Episode 905 finished! Frames: 175 Reward: -67963.91325449645\n",
            "Episode 906 finished! Frames: 170 Reward: -69098.59835728092\n",
            "Episode 907 finished! Frames: 126 Reward: -76196.36713519073\n",
            "Episode 908 finished! Frames: 81 Reward: -84374.10288092225\n",
            "Episode 909 finished! Frames: 123 Reward: -76887.51855092417\n",
            "Episode 910 finished! Frames: 113 Reward: -78708.33491086995\n",
            "Episode 911 finished! Frames: 73 Reward: -85850.9233293373\n",
            "Episode 912 finished! Frames: 205 Reward: -63294.88197419484\n",
            "Episode 913 finished! Frames: 138 Reward: -74310.6151406314\n",
            "Episode 914 finished! Frames: 132 Reward: -75386.7740370857\n",
            "Episode 915 finished! Frames: 122 Reward: -77034.84919625187\n",
            "Episode 916 finished! Frames: 186 Reward: -66040.20174227125\n",
            "Episode 917 finished! Frames: 92 Reward: -82362.30500685044\n",
            "Episode 918 finished! Frames: 138 Reward: -74515.84772291177\n",
            "Episode 919 finished! Frames: 217 Reward: -60642.75346197775\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 920 finished! Frames: 149 Reward: -72529.18521581756\n",
            "Episode 921 finished! Frames: 132 Reward: -75550.98402459666\n",
            "Episode 922 finished! Frames: 90 Reward: -82684.01629714786\n",
            "Episode 923 finished! Frames: 178 Reward: -68494.73923103319\n",
            "Episode 924 finished! Frames: 135 Reward: -75056.8734612845\n",
            "Episode 925 finished! Frames: 66 Reward: -87150.6566188379\n",
            "Episode 926 finished! Frames: 96 Reward: -82460.0453606795\n",
            "Episode 927 finished! Frames: 130 Reward: -75894.81814604877\n",
            "Episode 928 finished! Frames: 188 Reward: -68128.43627464634\n",
            "Episode 929 finished! Frames: 132 Reward: -75780.09550100901\n",
            "Episode 930 finished! Frames: 103 Reward: -80422.96386880073\n",
            "Episode 931 finished! Frames: 216 Reward: -61520.64211676895\n",
            "Episode 932 finished! Frames: 316 Reward: -45867.6628413966\n",
            "Episode 933 finished! Frames: 74 Reward: -85687.61931003744\n",
            "Episode 934 finished! Frames: 171 Reward: -70169.5355001333\n",
            "Episode 935 finished! Frames: 55 Reward: -89267.29687812366\n",
            "Episode 936 finished! Frames: 164 Reward: -72648.27538448141\n",
            "Episode 937 finished! Frames: 98 Reward: -81380.11815908618\n",
            "Episode 938 finished! Frames: 83 Reward: -84022.51225263723\n",
            "Episode 939 finished! Frames: 70 Reward: -86390.92380886135\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 940 finished! Frames: 159 Reward: -71192.61766562052\n",
            "Episode 941 finished! Frames: 92 Reward: -82380.840836833\n",
            "Episode 942 finished! Frames: 106 Reward: -79834.05722069753\n",
            "Episode 943 finished! Frames: 145 Reward: -74049.56019827777\n",
            "Episode 944 finished! Frames: 95 Reward: -81862.8244477656\n",
            "Episode 945 finished! Frames: 112 Reward: -78712.46802949184\n",
            "Episode 946 finished! Frames: 118 Reward: -77846.37357493452\n",
            "Episode 947 finished! Frames: 50 Reward: -90219.13146026354\n",
            "Episode 948 finished! Frames: 58 Reward: -88685.71973034083\n",
            "Episode 949 finished! Frames: 113 Reward: -78592.35920098054\n",
            "Episode 950 finished! Frames: 225 Reward: -60520.961151316325\n",
            "Episode 951 finished! Frames: 252 Reward: -57340.530595857745\n",
            "Episode 952 finished! Frames: 84 Reward: -83825.34891621963\n",
            "Episode 953 finished! Frames: 80 Reward: -84515.3676771935\n",
            "Episode 954 finished! Frames: 72 Reward: -86052.51777202704\n",
            "Episode 955 finished! Frames: 75 Reward: -85465.08698704824\n",
            "Episode 956 finished! Frames: 74 Reward: -85681.55616976452\n",
            "Episode 957 finished! Frames: 76 Reward: -85307.94340974124\n",
            "Episode 958 finished! Frames: 137 Reward: -74382.78978453693\n",
            "Episode 959 finished! Frames: 92 Reward: -82370.15514276183\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 960 finished! Frames: 89 Reward: -82770.28659083886\n",
            "Episode 961 finished! Frames: 99 Reward: -81033.55934986194\n",
            "Episode 962 finished! Frames: 88 Reward: -83083.32193575054\n",
            "Episode 963 finished! Frames: 152 Reward: -74506.52285490301\n",
            "Episode 964 finished! Frames: 97 Reward: -81866.2417548805\n",
            "Episode 965 finished! Frames: 148 Reward: -72535.83667280307\n",
            "Episode 966 finished! Frames: 81 Reward: -84337.50940528898\n",
            "Episode 967 finished! Frames: 71 Reward: -86173.38159755894\n",
            "Episode 968 finished! Frames: 84 Reward: -83820.22240241217\n",
            "Episode 969 finished! Frames: 55 Reward: -89265.71825590843\n",
            "Episode 970 finished! Frames: 128 Reward: -76319.52357580823\n",
            "Episode 971 finished! Frames: 64 Reward: -87537.28383066566\n",
            "Episode 972 finished! Frames: 117 Reward: -77857.82889790532\n",
            "Episode 973 finished! Frames: 80 Reward: -84610.8538821502\n",
            "Episode 974 finished! Frames: 164 Reward: -69710.47534845506\n",
            "Episode 975 finished! Frames: 131 Reward: -75583.1282576847\n",
            "Episode 976 finished! Frames: 97 Reward: -81544.53435318719\n",
            "Episode 977 finished! Frames: 125 Reward: -76428.56143724674\n",
            "Episode 978 finished! Frames: 149 Reward: -72716.44917517179\n",
            "Episode 979 finished! Frames: 178 Reward: -68261.05375659902\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n",
            "Episode 980 finished! Frames: 88 Reward: -83828.27788523276\n",
            "Episode 981 finished! Frames: 97 Reward: -81292.66643680155\n",
            "Episode 982 finished! Frames: 103 Reward: -80397.15328408024\n",
            "Episode 983 finished! Frames: 103 Reward: -80552.53440205943\n",
            "Episode 984 finished! Frames: 105 Reward: -80020.23932422827\n",
            "Episode 985 finished! Frames: 173 Reward: -69546.82795533008\n",
            "Episode 986 finished! Frames: 72 Reward: -86186.54019003433\n",
            "Episode 987 finished! Frames: 264 Reward: -52344.12713542683\n",
            "Episode 988 finished! Frames: 119 Reward: -77720.28818516021\n",
            "Episode 989 finished! Frames: 85 Reward: -83496.96642909813\n",
            "Episode 990 finished! Frames: 78 Reward: -84931.338747637\n",
            "Episode 991 finished! Frames: 149 Reward: -73566.43356736135\n",
            "Episode 992 finished! Frames: 91 Reward: -82579.76035364007\n",
            "Episode 993 finished! Frames: 170 Reward: -68749.91184818378\n",
            "Episode 994 finished! Frames: 46 Reward: -91018.55000958034\n",
            "Episode 995 finished! Frames: 77 Reward: -85040.75064226778\n",
            "Episode 996 finished! Frames: 75 Reward: -85471.56921533914\n",
            "Episode 997 finished! Frames: 54 Reward: -89459.72902447487\n",
            "Episode 998 finished! Frames: 69 Reward: -86637.84133561228\n",
            "Episode 999 finished! Frames: 89 Reward: -82931.74264671904\n",
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/assets\n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "model = MyModel()\n",
        "for j in range(total_episodes):\n",
        "    with open('./replay/'+str(j)+'.txt', \"w\") as f:\n",
        "        G = game_with_op(Player(320, 400), copy.deepcopy(data))\n",
        "        flag = True\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            if flag:\n",
        "                img = G.get_img()\n",
        "                img = proc(img)\n",
        "                img, stacked_imgs = stack_img(stacked_imgs, img, True)\n",
        "                flag = False\n",
        "            action = model.predict(img)\n",
        "            f.write(str(action)+'\\n')\n",
        "            reward, done = G.op(action)\n",
        "            total_reward += reward\n",
        "            #print('Frame: {}, action: {}, reward: {:.0f}'.format(G.frame, action, total_reward))\n",
        "            #print('X: {:.1f} Y: {:.1f}'.format(G.player.x, G.player.y))\n",
        "            if done:\n",
        "                next_img = np.zeros(new_img_size)\n",
        "                next_img, stacked_imgs = stack_img(stacked_imgs, next_img)\n",
        "                memory.remember((img, action, reward, next_img))\n",
        "                print(\"Episode {} finished! Frames: {} Reward: {}\".format(j, G.frame, total_reward))\n",
        "            else:\n",
        "                next_img = G.get_img()\n",
        "                next_img = proc(next_img)\n",
        "                #while (next_img != 0.7).all():\n",
        "                    #G.op(0)\n",
        "                    #f.write('0\\n')\n",
        "                    #print('skipping')\n",
        "                    #next_img = G.get_img()\n",
        "                next_img, stacked_imgs = stack_img(stacked_imgs, next_img)\n",
        "                memory.remember((img, action, reward, next_img))\n",
        "                img = next_img\n",
        "            \n",
        "            batch = memory.sample()\n",
        "            img_batch = np.array([each[0] for each in batch], ndmin=3)\n",
        "            action_batch = np.array([each[1] for each in batch])\n",
        "            reward_batch = np.array([each[2] for each in batch]) \n",
        "            next_img_batch = np.array([each[3] for each in batch], ndmin=3)\n",
        "\n",
        "            next_img_batch_Q = model.predicts(next_img_batch)\n",
        "            img_batch_Q = model.predicts(img_batch)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                img_batch_Q[i][action_batch[i]] = (1 - 0.1) * img_batch_Q[i][action_batch[i]] + \\\n",
        "                0.1 * (reward_batch[i] + gamma * np.amax(next_img_batch_Q[i]))\n",
        "            model.model.fit(img_batch, img_batch_Q, verbose = 0)\n",
        "            if done:\n",
        "                if j % 20 == 19:\n",
        "                    model.model.save('./drive/MyDrive/models/')\n",
        "                break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.model.save('content/drive/MyDrive/model/copy1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvYdNSnjVEGP",
        "outputId": "e54e86a7-dfd2-4fb5-d6f5-60d3880e9a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: content/drive/MyDrive/model/copy1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gpWR7-JSq4L"
      },
      "outputs": [],
      "source": [
        "#train2\n",
        "model = MyModel()\n",
        "for j in range(total_episodes):\n",
        "    with open('./replay/'+str(j)+'.txt', \"w\") as f:\n",
        "        G = game_with_op(Player(320, 400), copy.deepcopy(data))\n",
        "        flag = True\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            if flag:\n",
        "                img = G.get_img()\n",
        "                img, stacked_imgs = stack_img(stacked_imgs, img, True)\n",
        "                flag = False\n",
        "            action = model.predict(img)\n",
        "            f.write(str(action)+'\\n')\n",
        "            reward, done = G.op(action)\n",
        "            total_reward += reward\n",
        "            #print('Frame: {}, action: {}, reward: {:.0f}'.format(G.frame, action, total_reward))\n",
        "            #print('X: {:.1f} Y: {:.1f}'.format(G.player.x, G.player.y))\n",
        "            if done:\n",
        "                next_img = np.zeros(state_size[:2])\n",
        "                next_img, stacked_imgs = stack_img(stacked_imgs, next_img)\n",
        "                memory.remember((img, action, reward, next_img))\n",
        "                print(\"Episode {} finished! Frames: {} Reward: {}\".format(j, G.frame, total_reward))\n",
        "            else:\n",
        "                next_img = G.get_img()\n",
        "                while (next_img != 0.7).all():\n",
        "                    G.op(0)\n",
        "                    f.write('0\\n')\n",
        "                    print('skipping')\n",
        "                    next_img = G.get_img()\n",
        "                next_img, stacked_imgs = stack_img(stacked_imgs, next_img)\n",
        "                memory.remember((img, action, reward, next_img))\n",
        "                img = next_img\n",
        "            \n",
        "\n",
        "            if done:\n",
        "                for cc in range(10):\n",
        "                    batch = memory.sample(50 * batch_size)\n",
        "                    img_batch = np.array([each[0] for each in batch], ndmin=3)\n",
        "                    action_batch = np.array([each[1] for each in batch])\n",
        "                    reward_batch = np.array([each[2] for each in batch]) \n",
        "                    next_img_batch = np.array([each[3] for each in batch], ndmin=3)\n",
        "\n",
        "                    next_img_batch_Q = model.predicts(next_img_batch)\n",
        "                    img_batch_Q = model.predicts(img_batch)\n",
        "                    for i in range(batch_size):\n",
        "                        img_batch_Q[i][action_batch[i]] = (1 - 0.1) * img_batch_Q[i][action_batch[i]] + \\\n",
        "                        0.1 * (reward_batch[i] + gamma * np.amax(next_img_batch_Q[i]))\n",
        "                    model.model.fit(img_batch, img_batch_Q, verbose = 0)\n",
        "                if j % 20 == 0:\n",
        "                    model.model.save('./drive/MyDrive/models/')\n",
        "                break\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of test_for_DQN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}